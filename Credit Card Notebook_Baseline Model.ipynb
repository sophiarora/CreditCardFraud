{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Notebook_Baseline Model\n",
    "In the following code I use the dummy classifier from scikit learn package to create the baseline for our analysis. Dummy classifier produce randomised prediction for the given data based on probability of the calss presented in the dataset. Check out documentation [here](http://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html)\n",
    "\n",
    "As we could see from the below analysis, dummy classifier did a good job in terms of general accuracy by predicting most transactions as normal ones. If we assume that FN(transactions that are predictied normal are actually fraud) are more costly. And we assume FN:FP as 1000:1, we could get the cost of Dummy classifier is 71,088. While the overall accuracy is high, as we predicited only one fraud transaction correctly. Precision and Recall are both very low. Indicating that dummy classifier is not a good strategy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/MiroWang/Desktop/Github Repo/CreditFraudData\n"
     ]
    }
   ],
   "source": [
    "% cd /Users/MiroWang/Desktop/Github Repo/CreditFraudData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_frame = pd.read_csv(\"train_frame_creditcard.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205060, 29) (51266, 29) (205060,) (51266,)\n"
     ]
    }
   ],
   "source": [
    "#use the train frame to train and validate\n",
    "#stratified split again to fit data\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "X_dummy = train_frame[train_frame.columns[:-1]].as_matrix()\n",
    "y_dummy = train_frame['Class']\n",
    "\n",
    "strsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=36)\n",
    "for train_index, test_index in strsplit.split(X_dummy, y_dummy):\n",
    "    X_train_dummy, X_test_dummy = X_dummy[train_index], X_dummy[test_index]\n",
    "    y_train_dummy, y_test_dummy = y_dummy[train_index], y_dummy[test_index]\n",
    "    \n",
    "print(X_train_dummy.shape, X_test_dummy.shape, y_train_dummy.shape, y_test_dummy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_curve, auc, confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Time: 0.008042440982535481 seconds\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "start = timeit.default_timer()\n",
    "dummy = DummyClassifier()\n",
    "dummy.fit(X_train_dummy, y_train_dummy)\n",
    "stop = timeit.default_timer()\n",
    "print(\"Fitting Time: %s seconds\" % (stop - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_cm = confusion_matrix(y_test_dummy, dummy.predict(X_test_dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost of dummy classifier 88071\n"
     ]
    }
   ],
   "source": [
    "print (\"cost of dummy classifier %s\" % (dummy_cm[0][1]*1+ dummy_cm[1][0]*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall of dummy classifier 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"recall of dummy classifier %s\" % precision_score(y_test_dummy, dummy.predict(X_test_dummy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51106    71]\n",
      " [   88     1]]\n"
     ]
    }
   ],
   "source": [
    "print (dummy_cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
